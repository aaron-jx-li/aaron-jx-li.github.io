---
layout: about
title: about
permalink: /
# subtitle: <a href='#'>Affiliations</a>. Address. Contacts. Motto. Etc.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>Berkeley, CA, 94720</p>

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I am a first-year CS PhD student at UC Berkeley advised by Prof. [Bin Yu](https://binyu.stat.berkeley.edu/) and Prof. [Ion Stoica](https://people.eecs.berkeley.edu/~istoica/). I'm affiliated with [Sky Computing Lab](https://sky.cs.berkeley.edu/) and [BAIR](https://bair.berkeley.edu/). I completed my Master’s degree in Computational Science and Engineering at Harvard University, where I was fortunate to be advised by Prof. [Hima Lakkaraju](https://himalakkaraju.github.io). Prior to that, I earned my Bachelor’s degree from UC Berkeley, double majoring in Computer Science and Psychology.

I've been working on the intersections of Trustworthy Machine Learning, LLMs, and Mechanistic Interpretability. Moving forward, I'm also broadly interested in LLM evaluation and alignment. The two overarching research questions I aim to address are:

(1) How could we obtain reliable interpretations of learning dynamics and explanations of observed model behaviors?

(2) How could we leverage such actionable insights to improve next-generation foundation models?