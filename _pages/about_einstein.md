I am an incoming CS PhD student at UC Berkeley affiliated with [BAIR](https://bair.berkeley.edu/), and I will be coadvised by Prof. [Bin Yu](https://binyu.stat.berkeley.edu/) and Prof. [Ion Stoica](https://people.eecs.berkeley.edu/~istoica/). I recently graduated from Harvard University as a Master's student in Computational Science and Engineering, where I've been fortunate to be advised by Prof. [Hima Lakkaraju](https://himalakkaraju.github.io). Prior to that, I received my Bachelor's degree from UC Berkeley with a double major in Computer Science and Psychology, as part of the EECS Honors Program. 


I've been working on the intersections of Trustworthy Machine Learning, Large Language Models, and Mechanistic Interpretability. I'm also broadly interested in LLM evaluation and alignment. The two overarching research questions I aim to address are:

(1) How could we obtain reliable interpretations of learning dynamics and explanations of observed model behaviors?

(2) How could we leverage such understanding to improve next-generation foundation models?

