---
---


@InProceedings{li2023improving,
  abbr={ICML},
  arxiv={2307.03887},
  abstract={In recent years, work has gone into developing deep interpretable methods for image classification that clearly attributes a model's output to specific features of the data. One such of these methods is the Prototypical Part Network (ProtoPNet), which attempts to classify images based on meaningful parts of the input. While this architecture is able to produce visually interpretable classifications, it often learns to classify based on parts of the image that are not semantically meaningful. To address this problem, we propose the Reward Reweighing, Reselecting, and Retraining (R3) post-processing framework, which performs three additional corrective updates to a pretrained ProtoPNet in an offline and efficient manner. The first two steps involve learning a reward model based on collected human feedback and then aligning the prototypes with human preferences. The final step is retraining, which realigns the base features and the classifier layer of the original model with the updated prototypes. We find that our R3 framework consistently improves both the interpretability and the predictive accuracy of ProtoPNet and its variants.},
  bibtex_show={true},
  title={Improving Prototypical Visual Explanations with Reward Reweighing, Reselection, and Retraining},
  author={Li, Aaron J. and Netzorg, Robin and Cheng, Zhihan and Zhang, Zhuoqin and Yu, Bin},
  booktitle={Proceedings of the 41st International Conference on Machine Learning},
  year={2023},
  publisher={PMLR},
  selected={true},
  venue={ICML 2024},
  preview={r3_ppnet.png}
}
