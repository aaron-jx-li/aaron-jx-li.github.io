I am an incoming CS PhD student at UC Berkeley affiliated with [BAIR](https://bair.berkeley.edu/), and I will be coadvised by Prof. [Bin Yu](https://binyu.stat.berkeley.edu/) and Prof. [Ion Stoica](https://people.eecs.berkeley.edu/~istoica/). I recently completed my Master’s degree in Computational Science and Engineering at Harvard University, where I was fortunate to be advised by Prof. [Hima Lakkaraju](https://himalakkaraju.github.io). Prior to that, I earned my Bachelor’s degree from UC Berkeley, double majoring in Computer Science and Psychology through the EECS Honors Program.

I've been working on the intersections of Trustworthy Machine Learning, LLMs, and Mechanistic Interpretability. Moving forward, I'm also broadly interested in LLM evaluation and alignment. The two overarching research questions I aim to address are:

(1) How could we obtain reliable interpretations of learning dynamics and explanations of observed model behaviors?

(2) How could we leverage such actionable insights to improve next-generation foundation models?